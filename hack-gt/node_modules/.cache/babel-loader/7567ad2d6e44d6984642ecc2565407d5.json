{"ast":null,"code":"var _jsxFileName = \"/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx\";\nimport React, { useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nexport const Dictaphone = () => {\n  const {\n    transcript,\n    resetTranscript\n  } = useSpeechRecognition();\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  useEffect(() => {\n    SpeechRecognition.startListening;\n  }, []);\n  return /*#__PURE__*/React.createElement(\"div\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 19,\n      columnNumber: 5\n    }\n  }, /*#__PURE__*/React.createElement(\"button\", {\n    onClick: SpeechRecognition.startListening,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 7\n    }\n  }, \"Start\"), /*#__PURE__*/React.createElement(\"button\", {\n    onClick: SpeechRecognition.stopListening,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 21,\n      columnNumber: 7\n    }\n  }, \"Stop\"), /*#__PURE__*/React.createElement(\"button\", {\n    onClick: resetTranscript,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 22,\n      columnNumber: 7\n    }\n  }, \"Reset\"), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 7\n    }\n  }, transcript));\n};","map":{"version":3,"sources":["/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx"],"names":["React","useEffect","SpeechRecognition","useSpeechRecognition","Dictaphone","transcript","resetTranscript","browserSupportsSpeechRecognition","startListening","stopListening"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IACEC,oBADF,QAEO,0BAFP;AAIA,OAAO,MAAMC,UAAU,GAAG,MAAM;AAC9B,QAAM;AAAEC,IAAAA,UAAF;AAAcC,IAAAA;AAAd,MAAkCH,oBAAoB,EAA5D;;AAEA,MAAI,CAACD,iBAAiB,CAACK,gCAAlB,EAAL,EAA2D;AACzD,WAAO,IAAP;AACD;;AAEDN,EAAAA,SAAS,CAAC,MAAM;AACVC,IAAAA,iBAAiB,CAACM,cAAlB;AACL,GAFQ,EAEN,EAFM,CAAT;AAKA,sBACE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE;AAAQ,IAAA,OAAO,EAAEN,iBAAiB,CAACM,cAAnC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aADF,eAEE;AAAQ,IAAA,OAAO,EAAEN,iBAAiB,CAACO,aAAnC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,YAFF,eAGE;AAAQ,IAAA,OAAO,EAAEH,eAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aAHF,eAIE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAID,UAAJ,CAJF,CADF;AAQD,CApBM","sourcesContent":["import React, { useEffect } from \"react\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\n\nexport const Dictaphone = () => {\n  const { transcript, resetTranscript } = useSpeechRecognition();\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  useEffect(() => {\n        SpeechRecognition.startListening\n  }, [])\n\n\n  return (\n    <div>\n      <button onClick={SpeechRecognition.startListening}>Start</button>\n      <button onClick={SpeechRecognition.stopListening}>Stop</button>\n      <button onClick={resetTranscript}>Reset</button>\n      <p>{transcript}</p>\n    </div>\n  );\n};\n"]},"metadata":{},"sourceType":"module"}