{"ast":null,"code":"var _jsxFileName = \"/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx\";\nimport React, { useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport { useVoiceCommands } from \"../data/useVoiceCommands\";\nimport MicIcon from \"@material-ui/icons/Mic\";\nimport { VoicePlayer, VoiceRecognition } from \"react-voice-components\";\nexport const Dictaphone = () => {\n  const {\n    transcript,\n    resetTranscript\n  } = useSpeechRecognition();\n  const [voice, setVoice] = React.useState(\"I am listening...\");\n\n  const resetVoice = str => {\n    setVoice(str);\n  };\n\n  useVoiceCommands({\n    transcript,\n    resetTranscript,\n    resetVoice\n  });\n  useEffect(() => {\n    SpeechRecognition.startListening({\n      continuous: true\n    });\n  }, []);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  return /*#__PURE__*/React.createElement(React.Fragment, null, /*#__PURE__*/React.createElement(Speech, {\n    text: transcript,\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 29,\n      columnNumber: 7\n    }\n  }), /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      display: \"flex\",\n      flexDirection: \"row\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(MicIcon, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 31,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"span\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 9\n    }\n  }, voice)), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 34,\n      columnNumber: 7\n    }\n  }, transcript));\n};","map":{"version":3,"sources":["/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx"],"names":["React","useEffect","SpeechRecognition","useSpeechRecognition","useVoiceCommands","MicIcon","VoicePlayer","VoiceRecognition","Dictaphone","transcript","resetTranscript","voice","setVoice","useState","resetVoice","str","startListening","continuous","browserSupportsSpeechRecognition","display","flexDirection"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IACEC,oBADF,QAEO,0BAFP;AAGA,SAASC,gBAAT,QAAiC,0BAAjC;AACA,OAAOC,OAAP,MAAoB,wBAApB;AACA,SAASC,WAAT,EAAsBC,gBAAtB,QAA8C,wBAA9C;AAEA,OAAO,MAAMC,UAAU,GAAG,MAAM;AAC9B,QAAM;AAAEC,IAAAA,UAAF;AAAcC,IAAAA;AAAd,MAAkCP,oBAAoB,EAA5D;AACA,QAAM,CAACQ,KAAD,EAAQC,QAAR,IAAoBZ,KAAK,CAACa,QAAN,CAAe,mBAAf,CAA1B;;AAEA,QAAMC,UAAU,GAAIC,GAAD,IAAS;AAC1BH,IAAAA,QAAQ,CAACG,GAAD,CAAR;AACD,GAFD;;AAIAX,EAAAA,gBAAgB,CAAC;AAAEK,IAAAA,UAAF;AAAcC,IAAAA,eAAd;AAA+BI,IAAAA;AAA/B,GAAD,CAAhB;AAEAb,EAAAA,SAAS,CAAC,MAAM;AACdC,IAAAA,iBAAiB,CAACc,cAAlB,CAAiC;AAAEC,MAAAA,UAAU,EAAE;AAAd,KAAjC;AACD,GAFQ,EAEN,EAFM,CAAT;;AAIA,MAAI,CAACf,iBAAiB,CAACgB,gCAAlB,EAAL,EAA2D;AACzD,WAAO,IAAP;AACD;;AAED,sBACE,uDACE,oBAAC,MAAD;AAAQ,IAAA,IAAI,EAAET,UAAd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAEE;AAAK,IAAA,KAAK,EAAE;AAAEU,MAAAA,OAAO,EAAE,MAAX;AAAmBC,MAAAA,aAAa,EAAE;AAAlC,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAOT,KAAP,CAFF,CAFF,eAME;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAIF,UAAJ,CANF,CADF;AAUD,CA5BM","sourcesContent":["import React, { useEffect } from \"react\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\nimport { useVoiceCommands } from \"../data/useVoiceCommands\";\nimport MicIcon from \"@material-ui/icons/Mic\";\nimport { VoicePlayer, VoiceRecognition } from \"react-voice-components\";\n\nexport const Dictaphone = () => {\n  const { transcript, resetTranscript } = useSpeechRecognition();\n  const [voice, setVoice] = React.useState(\"I am listening...\");\n\n  const resetVoice = (str) => {\n    setVoice(str);\n  };\n\n  useVoiceCommands({ transcript, resetTranscript, resetVoice });\n\n  useEffect(() => {\n    SpeechRecognition.startListening({ continuous: true });\n  }, []);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  return (\n    <>\n      <Speech text={transcript} />\n      <div style={{ display: \"flex\", flexDirection: \"row\" }}>\n        <MicIcon />\n        <span>{voice}</span>\n      </div>\n      <p>{transcript}</p>\n    </>\n  );\n};\n"]},"metadata":{},"sourceType":"module"}