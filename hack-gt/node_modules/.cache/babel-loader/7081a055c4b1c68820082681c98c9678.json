{"ast":null,"code":"var _jsxFileName = \"/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx\";\nimport React, { useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport { useVoiceCommands } from \"../data/useVoiceCommands\";\nimport MicIcon from \"@material-ui/icons/Mic\";\nexport const Dictaphone = () => {\n  const {\n    transcript,\n    resetTranscript\n  } = useSpeechRecognition();\n  const [voice, setVoice] = React.useState();\n\n  const resetVoice = sdtr => {\n    setVoice();\n  };\n\n  useVoiceCommands({\n    transcript,\n    resetTranscript\n  });\n  useEffect(() => {\n    SpeechRecognition.startListening({\n      continuous: true\n    });\n  }, []);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  return /*#__PURE__*/React.createElement(React.Fragment, null, /*#__PURE__*/React.createElement(\"div\", {\n    style: {\n      display: \"flex\",\n      flexDirection: \"row\"\n    },\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 28,\n      columnNumber: 7\n    }\n  }, /*#__PURE__*/React.createElement(MicIcon, {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 29,\n      columnNumber: 9\n    }\n  }), /*#__PURE__*/React.createElement(\"span\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 30,\n      columnNumber: 9\n    }\n  }, \"I am listening...\")), /*#__PURE__*/React.createElement(\"p\", {\n    __self: this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 32,\n      columnNumber: 7\n    }\n  }, transcript));\n};","map":{"version":3,"sources":["/Users/thotra/Desktop/hack-gt/src/components/Dictaphone.jsx"],"names":["React","useEffect","SpeechRecognition","useSpeechRecognition","useVoiceCommands","MicIcon","Dictaphone","transcript","resetTranscript","voice","setVoice","useState","resetVoice","sdtr","startListening","continuous","browserSupportsSpeechRecognition","display","flexDirection"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,iBAAP,IACEC,oBADF,QAEO,0BAFP;AAGA,SAASC,gBAAT,QAAiC,0BAAjC;AACA,OAAOC,OAAP,MAAoB,wBAApB;AAEA,OAAO,MAAMC,UAAU,GAAG,MAAM;AAC9B,QAAM;AAAEC,IAAAA,UAAF;AAAcC,IAAAA;AAAd,MAAkCL,oBAAoB,EAA5D;AACA,QAAM,CAACM,KAAD,EAAQC,QAAR,IAAoBV,KAAK,CAACW,QAAN,EAA1B;;AAEA,QAAMC,UAAU,GAAIC,IAAD,IAAU;AAC3BH,IAAAA,QAAQ;AACT,GAFD;;AAIAN,EAAAA,gBAAgB,CAAC;AAAEG,IAAAA,UAAF;AAAcC,IAAAA;AAAd,GAAD,CAAhB;AAEAP,EAAAA,SAAS,CAAC,MAAM;AACdC,IAAAA,iBAAiB,CAACY,cAAlB,CAAiC;AAAEC,MAAAA,UAAU,EAAE;AAAd,KAAjC;AACD,GAFQ,EAEN,EAFM,CAAT;;AAIA,MAAI,CAACb,iBAAiB,CAACc,gCAAlB,EAAL,EAA2D;AACzD,WAAO,IAAP;AACD;;AAED,sBACE,uDACE;AAAK,IAAA,KAAK,EAAE;AAAEC,MAAAA,OAAO,EAAE,MAAX;AAAmBC,MAAAA,aAAa,EAAE;AAAlC,KAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACE,oBAAC,OAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,yBAFF,CADF,eAKE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAIX,UAAJ,CALF,CADF;AASD,CA3BM","sourcesContent":["import React, { useEffect } from \"react\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\nimport { useVoiceCommands } from \"../data/useVoiceCommands\";\nimport MicIcon from \"@material-ui/icons/Mic\";\n\nexport const Dictaphone = () => {\n  const { transcript, resetTranscript } = useSpeechRecognition();\n  const [voice, setVoice] = React.useState();\n\n  const resetVoice = (sdtr) => { \n    setVoice()\n  }\n\n  useVoiceCommands({ transcript, resetTranscript });\n\n  useEffect(() => {\n    SpeechRecognition.startListening({ continuous: true });\n  }, []);\n\n  if (!SpeechRecognition.browserSupportsSpeechRecognition()) {\n    return null;\n  }\n\n  return (\n    <>\n      <div style={{ display: \"flex\", flexDirection: \"row\" }}>\n        <MicIcon />\n        <span>I am listening...</span>\n      </div>\n      <p>{transcript}</p>\n    </>\n  );\n};\n"]},"metadata":{},"sourceType":"module"}